{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working in the iPython / Jupyter notebook system. I like these because they are a form of literate programming in which we can mix textbook instruction and explanations with code that can also be run and edited.\n",
    "\n",
    "The text and mathematics in the notebooks requires a little preliminary learning.\n",
    "\n",
    "### Markdown\n",
    "\n",
    "You can document your iPython notebooks by making some cells into **Markdown** cells. Markdown is a way of formatting text that is supposed to be almost as readable un-rendered as when it is tidied up. You might argue that it looks equally bad either way, but that's tough because the notebooks use it and that's how I want you to produce nice looking output to hand in as an assignment !\n",
    "\n",
    "If you look at the **Markdown** cells as source code (by double-clicking on them) you will see how the raw text looks.\n",
    "\n",
    "### Maths\n",
    "\n",
    "In a browser, you can render beautiful equations using a javascript tool called **Mathjax** which is build into the iPython notebooks. \n",
    "\n",
    "\n",
    "You can build in symbols to your text such as $\\pi$ and $\\epsilon$ if you use the \\$ signs to indicate where your equations begin and end, and you know enough $\\LaTeX$ [try it here !](http://www.codecogs.com/latex/eqneditor.php) to get by.\n",
    "\n",
    "\n",
    "Equations in 'display' mode are written like this (again look at the source for this cell to see what is used)\n",
    "\n",
    "\\\\[ e^{i\\pi} + 1 = 0 \\\\]\n",
    "\n",
    "or even like this\n",
    "\n",
    "\\begin{equation}\n",
    "%%\n",
    "    \\nabla^4 \\psi = \\frac{\\partial T}{\\partial x}\n",
    "%%    \n",
    "\\end{equation}\n",
    "\n",
    "Go back to the rendered form of the cell by 'running' it.\n",
    "\n",
    "### Links \n",
    "\n",
    "[Markdown Website](http://daringfireball.net/projects/markdown/)\n",
    "\n",
    "[Mathjax Website](http://docs.mathjax.org)\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "The notebooks require you to install `cartopy` and `gdal` -- this should be possible with pip but it's not always trivial to do. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "We need to download some data for the examples. Some files are bundled with the notebooks because I am not smart enough to understand how to download them through the various web / ftp interfaces directly or I needed to filter or compress the information for the purposes of the class. Please go to the original sites if you need to use these data for anything other than the demonstrations in these notebooks.\n",
    "\n",
    "Most datasets are too large for the repository (and generally, that's not a place to keep anything which is not the primary target of revision management. The bundled data are compressed and will be unpacked (copied) to the `Resources` directory by the \"download\" functions in this notebook. If you mess them up, just run the download again. Anything that is undamaged will just be be skipped anyway.\n",
    "\n",
    "#### Global Magnetic Data\n",
    "\n",
    "Magnetic intensity data from [geomag.org](http://geomag.org/models/EMAG2/EMAG2_V2.tif)\n",
    "\n",
    "#### Topography data\n",
    "\n",
    "ETOPO1 images are from NOAA - we use their geotifs which are subsampled from the original (enormous) dataset but \n",
    "\n",
    "#### NASA Blue marble images\n",
    "\n",
    "Winter and Summer images for the Earth are grabbed for plotting examples. The winter ones (June) are used by default as these have less ice in the N. Hemisphere. \n",
    "\n",
    "#### Earthquake hypocentres\n",
    "\n",
    "Are grabbed from the [NEIC](http://earthquake.usgs.gov/earthquakes/search/) - they are in the geoJSON format since that is very simple to read with python. The downloads are limited at 20k events so the time and magnitude range is whatever it takes to get just under this limit. The filenames give clues about that, but, so does the catalogue itself once it is read in.\n",
    "\n",
    "#### Global age grid \n",
    "\n",
    "Taken from Earthbyte and reduced in size by throwing away the grid information and saving in compressed numpy format. \n",
    "\n",
    "#### Global strain rate\n",
    "\n",
    "I grabbed the second invariant of the strain rate from the [global strain rate map](http://gsrm.unavco.org/intro) project through the 'Jules Vernes' portal. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Here are some functions to download or install files. \n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "def download_file(url, local_filename, expected_size):\n",
    "    \n",
    "    \n",
    "# We might want to bundle some files if they are small / compressed or not readily available for download\n",
    "\n",
    "    if (os.path.isfile(url)):\n",
    "        shutil.copy(url, local_filename)\n",
    "    \n",
    "    else:\n",
    "        r = requests.get(url, stream=True)\n",
    "\n",
    "        start_time = time.time()\n",
    "        last_time = start_time\n",
    "        datasize = 0\n",
    "\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=10000000): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "                    f.flush()\n",
    "                    datasize += len(chunk)\n",
    "                    if (time.time() - last_time) > 2.5:\n",
    "                        print \"{:.1f} Mb in {:.1f}s / {}\".format(datasize / 1.0e6, time.time() - start_time, expected_size)\n",
    "                        last_time = time.time()\n",
    "\n",
    "    return \n",
    "\n",
    "import hashlib\n",
    "\n",
    "def md5sum(filename, blocksize=65536):\n",
    "    hash = hashlib.md5()\n",
    "    with open(filename, \"r+b\") as f:\n",
    "        for block in iter(lambda: f.read(blocksize), \"\"):\n",
    "            hash.update(block)\n",
    "    return hash.hexdigest()\n",
    "\n",
    "\n",
    "def download_cached_file(location_url, local_file, expected_md5, expected_size=\"Unknown\"):\n",
    "\n",
    "    try:\n",
    "        assert md5sum(local_file) == expected_md5\n",
    "        print \"Using cached file - {}\".format(local_file)\n",
    "        return(2)\n",
    "    \n",
    "    except (IOError, AssertionError) as error_info:\n",
    "        # No file or the wrong file ... best go download it\n",
    "        # print \"Assertion failed - {}\".format(sys.exc_info())\n",
    "        \n",
    "        try:\n",
    "            mag_data_file = download_file(location_url, local_file, expected_size)\n",
    "            print \"Downloaded from {}\".format( location_url )\n",
    "            return(1)\n",
    "\n",
    "        except:\n",
    "            print \"Unable to download {} [{}] \".format( location_url, sys.exc_info() )\n",
    "            return(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resources required for the tutorial\n",
    "# The checksum is to make sure any cached file is the right one.\n",
    "# If the checksum is wrong the file gets downloaded again.\n",
    "\n",
    "# Some of these files are local, stored in the repo in compressed form and installed into the\n",
    "# Resources directory. \n",
    "\n",
    "resource_list = [\n",
    "# Global magnetic data \n",
    "{\n",
    " \"local_file\":\"Resources/EMAG2_image_V2.tif\",\n",
    " \"md5\":\"20024c06fdabfa57e4f9efb4aabec198\",\n",
    " \"url\":\"http://geomag.org/models/EMAG2/EMAG2_image_V2.tif\",\n",
    " \"expected_size\":\"133Mb\"\n",
    "},\n",
    "    \n",
    "# Australian Mag Data from AuScope portal (built by hand)\n",
    "{\n",
    " \"local_file\":\"Resources/AusMagAll.tiff.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"Reference/AusMagAll.tiff.zip\",\n",
    " \"expected_size\":\"10Mb\"\n",
    "},\n",
    "    \n",
    "# Blue Marble Image Geotiff June 2004 (11Mb)  \n",
    "{\n",
    " \"local_file\": \"Resources/BlueMarbleNG-TB_2004-06-01_rgb_3600x1800.TIFF\",\n",
    " \"md5\": '55e1399674d43a26353d84c114d7ff80',\n",
    " \"url\":\"http://neo.sci.gsfc.nasa.gov/servlet/RenderData?si=526294&cs=rgb&format=TIFF&width=3600&height=1800\",\n",
    " \"expected_size\":\"11Mb\"\n",
    "},\n",
    "    \n",
    "    \n",
    "# Blue Marble Image with Bathymetry png - December 2004 \n",
    "{\n",
    " \"local_file\": \"Resources/BlueMarbleNG-TB_2004-12-01_rgb_3600x1800.TIFF\",\n",
    " \"md5\": '825da4b417ae19e24d2ea6db6cf8ad21',\n",
    " \"url\":\"http://neo.sci.gsfc.nasa.gov/servlet/RenderData?si=526311&cs=rgb&format=TIFF&width=3600&height=1800\",\n",
    " \"expected_size\":\"11Mb\"\n",
    "},\n",
    "    \n",
    "# Etopo1 - color image \n",
    "{\n",
    " \"local_file\": \"Resources/color_etopo1_ice_low.tif.zip\",\n",
    " \"md5\": '3f53d72e85393deb28874db0c76fbfcb',\n",
    " \"url\":\"https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/image/color_etopo1_ice_low.tif.zip\",\n",
    " \"expected_size\":\"35Mb\"\n",
    "},\n",
    "    \n",
    "# Etopo1 - bw shaded relief image \n",
    "{\n",
    " \"local_file\": \"Resources/etopo1_grayscale_hillshade.tif.zip\",\n",
    " \"md5\": 'f38b8dc6cd971d72e77edaa837d5b85c',\n",
    " \"url\":\"https://www.ngdc.noaa.gov/mgg/global/relief/ETOPO1/image/etopo1_grayscale_hillshade.tif.zip\",\n",
    " \"expected_size\":\"115Mb\"\n",
    "},\n",
    "        \n",
    "# Global age grid  [LOCAL]\n",
    "{\n",
    " \"local_file\":\"Resources/global_age_data.3.6.z.npz\",\n",
    " \"md5\":'',\n",
    " \"url\":\"Reference/global_age_data.3.6.z.npz\",\n",
    " \"expected_size\":\"22Mb\"\n",
    "},\n",
    "      \n",
    "# Global second invariant of strain rate [LOCAL]\n",
    "{\n",
    " \"local_file\":\"Resources/sec_invariant_strain_0.2.dat.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"Reference/sec_invariant_strain_0.2.dat.zip\",\n",
    " \"expected_size\":\"4Mb\"\n",
    "},\n",
    "  \n",
    "    \n",
    "# Earthquake data for various regions as json files [LOCAL]\n",
    "{\n",
    " \"local_file\":\"Resources/Earthquake_data.zip\",\n",
    " \"md5\":'',\n",
    " \"url\":\"Reference/Earthquake_data.zip\",\n",
    " \"expected_size\":\"4Mb\"\n",
    "},\n",
    "  \n",
    "    \n",
    "\n",
    "    \n",
    "       \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for resource in resource_list:\n",
    "    print \"\\nDownloading {:s}\".format(resource[\"local_file\"])\n",
    "    download_cached_file(resource[\"url\"], resource[\"local_file\"], resource[\"md5\"], resource[\"expected_size\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract any files that were downloaded as zip archives\n",
    "\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "for zipped in glob.glob(\"Resources/*.zip\"):\n",
    "    with zipfile.ZipFile(zipped) as zf:\n",
    "        zf.extractall(\"Resources\")\n",
    "        print \"Unzipped {}\".format(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md5sum(\"Resources/etopo1_grayscale_hillshade.tif.zip\") # if you add a new file, add the md5 checksum as well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%ls -l Resources/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
